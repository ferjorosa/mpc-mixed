{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 412)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load original data\n",
    "original_data = pd.read_csv(\"./original_data.csv\", sep=\";\")\n",
    "# Replace ? with NaN\n",
    "original_data = original_data.replace(\"?\", np.nan)\n",
    "original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    400.000000\n",
       "mean      26.737500\n",
       "std        2.480721\n",
       "min       21.000000\n",
       "25%       25.000000\n",
       "50%       27.000000\n",
       "75%       29.000000\n",
       "max       30.000000\n",
       "Name: moca, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[\"moca\"].dropna().astype(\"int64\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Select original attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Socio-demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_socio_demographic_cols = [\"patnum\", \"age\", \"sex\", \"pdonset\", \"durat_pd\"]\n",
    "original_socio_demographic = original_data[original_socio_demographic_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Hoehn-Yahr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_hoehn_yahr_cols = [\"hy\"]\n",
    "original_hoehn_yahr = original_data[original_hoehn_yahr_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - NMSS\n",
    "\n",
    "First we need to convert nmss variables from \"object\" to \"int\". Then, we generate the NMSS domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fer\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "original_nmss_cols = [\n",
    "    \"nmss1f\", \"nmss1s\",\n",
    "    \"nmss2f\", \"nmss2s\",\n",
    "    \"nmss3f\", \"nmss3s\",\n",
    "    \"nmss4f\", \"nmss4s\",\n",
    "    \"nmss5f\", \"nmss5s\",\n",
    "    \"nmss6f\", \"nmss6s\",\n",
    "    \"nmss7f\", \"nmss7s\",\n",
    "    \"nmss8f\", \"nmss8s\",\n",
    "    \"nmss9f\", \"nmss9s\",\n",
    "    \"nmss10f\", \"nmss10s\",\n",
    "    \"nmss11f\", \"nmss11s\",\n",
    "    \"nmss12f\", \"nmss12s\",\n",
    "    \"nmss13f\", \"nmss13s\",\n",
    "    \"nmss14f\", \"nmss14s\",\n",
    "    \"nmss15f\", \"nmss15s\",\n",
    "    \"nmss16f\", \"nmss16s\",\n",
    "    \"nmss17f\", \"nmss17s\",\n",
    "    \"nmss18f\", \"nmss18s\",\n",
    "    \"nmss19f\", \"nmss19s\",\n",
    "    \"nmss20f\", \"nmss20s\",\n",
    "    \"nmss21f\", \"nmss21s\",\n",
    "    \"nmss22f\", \"nmss22s\",\n",
    "    \"nmss23f\", \"nmss23s\",\n",
    "    \"nmss24f\", \"nmss24s\",\n",
    "    \"nmss25f\", \"nmss25s\",\n",
    "    \"nmss26f\", \"nmss26s\",\n",
    "    \"nmss27f\", \"nmss27s\",\n",
    "    \"nmss28f\", \"nmss28s\",\n",
    "    \"nmss29f\", \"nmss29s\",\n",
    "    \"nmss30f\", \"nmss30s\",\n",
    "]\n",
    "\n",
    "original_nmss = original_data[original_nmss_cols]\n",
    "\n",
    "for col in original_nmss_cols:\n",
    "    original_nmss[col] = original_data[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - UPDRS - Motor\n",
    "\n",
    "Manually select those variables that represent motor symptoms corresponding to the \"Part 2: Part II: Motor Aspects of Experiences of Daily Living (M-EDL)\", \"Part 3: Motor examination\", and \"Part 4: Motor complications\" domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fer\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Fer\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "original_updrs_motor_cols = [\n",
    "    # M-EDL\n",
    "    \"mdsupdrs2_1\", \"mdsupdrs2_2\", \"mdsupdrs2_3\", \"mdsupdrs2_4\", \"mdsupdrs2_5\", \"mdsupdrs2_6\", \"mdsupdrs2_7\", \"mdsupdrs2_8\", \"mdsupdrs2_9\",\n",
    "    \"mdsupdrs2_10\", \"mdsupdrs2_11\", \"mdsupdrs2_12\", \"mdsupdrs2_13\",\n",
    "    # Motor examination\n",
    "    \"mdsupdrs3_1\",\"mdsupdrs3_2\",\"mdsupdrs3_3a\",\"mdsupdrs3_3b\",\"mdsupdrs3_3c\",\"mdsupdrs3_3d\",\"mdsupdrs3_3e\",\"mdsupdrs3_4a\",\"mdsupdrs3_4b\",\n",
    "    \"mdsupdrs3_5a\",\"mdsupdrs3_5b\",\"mdsupdrs3_6a\",\"mdsupdrs3_6b\",\"mdsupdrs3_7a\",\"mdsupdrs3_7b\",\"mdsupdrs3_8a\",\"mdsupdrs3_8b\",\"mdsupdrs3_9\",\n",
    "    \"mdsupdrs3_10\",\"mdsupdrs3_11\",\"mdsupdrs3_12\",\"mdsupdrs3_13\",\"mdsupdrs3_14\",\"mdsupdrs3_15a\",\"mdsupdrs3_15b\",\"mdsupdrs3_16a\",\"mdsupdrs3_16b\",\n",
    "    \"mdsupdrs3_17a\",\"mdsupdrs3_17b\",\"mdsupdrs3_17c\",\"mdsupdrs3_17d\",\"mdsupdrs3_17e\",\"mdsupdrs3_18\",\n",
    "    # Motor complications\n",
    "    \"mdsupdrs4_1\",\"mdsupdrs4_2\",\"mdsupdrs4_3\",\"mdsupdrs4_4\",\"mdsupdrs4_5\",\"mdsupdrs4_6\"\n",
    "]\n",
    "original_updrs_motor = original_data[original_updrs_motor_cols]\n",
    "\n",
    "for col in original_updrs_motor.columns:\n",
    "    original_updrs_motor[col] = pd.to_numeric(original_updrs_motor[col])\n",
    "    \n",
    "for col in original_updrs_motor.columns:\n",
    "    original_updrs_motor[col] = original_updrs_motor[col].astype(\"float64\")\n",
    "\n",
    "#original_updrs_motor.dtypes\n",
    "#original_updrs_motor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 - Combine them all\n",
    "\n",
    "Once selected, combine all data frames in a single one, which we are going to use to locate missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = pd.concat([original_socio_demographic, original_hoehn_yahr, original_nmss, original_updrs_motor], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Missing data\n",
    "\n",
    "Count missing values in each column, then filter those rows with misssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = data_combined.isnull()\n",
    "true_counts = [(column, missing_data[column].values.sum()) for column in missing_data.columns]\n",
    "false_counts = [(column, (~missing_data[column].values).sum()) for column in missing_data.columns]\n",
    "true_counts.sort(key=lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a concentration of missing values on certain variables of the MDS-NMS and MDS-UPDRS scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347, 118)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_missing = data_combined.dropna()\n",
    "data_no_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patnum          object\n",
       "age              int64\n",
       "sex              int64\n",
       "pdonset          int64\n",
       "durat_pd         int64\n",
       "                ...   \n",
       "mdsupdrs4_2    float64\n",
       "mdsupdrs4_3    float64\n",
       "mdsupdrs4_4    float64\n",
       "mdsupdrs4_5    float64\n",
       "mdsupdrs4_6    float64\n",
       "Length: 118, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combined.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Generate final attributes\n",
    "We have two datasets: \n",
    "* One with missing values <code>data_combined</code> (402, 96)\n",
    "* One without them <code>data_no_missing</code> (352, 96)\n",
    "\n",
    "By default we are going to select the dataset with missing values because our multidimensional clustering method can deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 118)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_combined\n",
    "#data = data_no_missing\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - NMSS\n",
    "\n",
    "For this, we are going to combine all the attributes of the same subscale (A, B, C, etc) into a single attribute, following the work of Chaudhuri et al. (2007). \n",
    "\n",
    "* **Cardiovascular** (2 attributes)\n",
    "* **Sleep/Fatigue** (4 attributes)\n",
    "* **Mood/Cognition** (6 attributes)\n",
    "* **Perception/Hallucinations** (3 attributes)\n",
    "* **Attention/Memory** (3 attributes)\n",
    "* **Gastrointestinal** (3 attributes)\n",
    "* **Urinary** (3 attributes)\n",
    "* **Sexual** (2 attributes)\n",
    "* **Smell** (1 attribute)\n",
    "* **Weight change** (1 attribute)\n",
    "* **Sweating** (1 attribute)\n",
    "\n",
    "We are going to divide the Miscellaneous domain intro 3 attributes, which are easier to analyze. Reason being, each one of them represent a different aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmss_domain_names=[\"cardiovascular\", \"sleep_fatigue\", \"mood_cognition\", \"hallucinations\", \"attention_memory\", \n",
    "            \"gastrointestinal\", \"urinary\", \"sexual\", \"smell\", \"weight_change\", \"sweating\"]\n",
    "\n",
    "nmss = pd.DataFrame(columns=nmss_domain_names)\n",
    "\n",
    "nmss[\"cardiovascular\"] = ((data[\"nmss1f\"] * data[\"nmss1s\"]) + \n",
    "                          (data[\"nmss2f\"] * data[\"nmss2s\"])) / 2\n",
    "\n",
    "nmss[\"sleep_fatigue\"] = ((data[\"nmss3f\"] * data[\"nmss3s\"]) +\n",
    "                        (data[\"nmss4f\"] * data[\"nmss4s\"]) +\n",
    "                        (data[\"nmss5f\"] * data[\"nmss5s\"]) +\n",
    "                        (data[\"nmss6f\"] * data[\"nmss6s\"])) / 4\n",
    "\n",
    "nmss[\"mood_cognition\"] = ((data[\"nmss7f\"] * data[\"nmss7s\"]) + \n",
    "           (data[\"nmss8f\"] * data[\"nmss8s\"]) +\n",
    "           (data[\"nmss9f\"] * data[\"nmss9s\"]) +\n",
    "           (data[\"nmss10f\"] * data[\"nmss10s\"]) +\n",
    "           (data[\"nmss11f\"] * data[\"nmss11s\"]) +\n",
    "           (data[\"nmss12f\"] * data[\"nmss12s\"])) / 6\n",
    "\n",
    "nmss[\"hallucinations\"] = ((data[\"nmss13f\"] * data[\"nmss13s\"]) + \n",
    "                         (data[\"nmss14f\"] * data[\"nmss14s\"]) + \n",
    "                         (data[\"nmss15f\"] * data[\"nmss15s\"])) / 3\n",
    "\n",
    "nmss[\"attention_memory\"] = ((data[\"nmss16f\"] * data[\"nmss16s\"]) +\n",
    "                            (data[\"nmss17f\"] * data[\"nmss17s\"]) +\n",
    "                            (data[\"nmss18f\"] * data[\"nmss18s\"])) / 3\n",
    "\n",
    "nmss[\"gastrointestinal\"] = ((data[\"nmss19f\"] * data[\"nmss19s\"]) +\n",
    "                            (data[\"nmss20f\"] * data[\"nmss20s\"]) +\n",
    "                            (data[\"nmss21f\"] * data[\"nmss21s\"])) / 3\n",
    "\n",
    "nmss[\"urinary\"] = ((data[\"nmss22f\"] * data[\"nmss22s\"]) +\n",
    "                            (data[\"nmss23f\"] * data[\"nmss23s\"]) +\n",
    "                            (data[\"nmss24f\"] * data[\"nmss24s\"])) / 3\n",
    "\n",
    "nmss[\"sexual\"] = ((data[\"nmss25f\"] * data[\"nmss25s\"]) +\n",
    "                            (data[\"nmss26f\"] * data[\"nmss26s\"])) / 2\n",
    "\n",
    "nmss[\"smell\"] = data[\"nmss28f\"] * data[\"nmss28s\"]\n",
    "\n",
    "nmss[\"weight_change\"] = data[\"nmss29f\"] * data[\"nmss29s\"]\n",
    "\n",
    "nmss[\"sweating\"] = data[\"nmss30f\"] * data[\"nmss30s\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - MDS-UPDRS\n",
    "\n",
    "There are multiple motor variables, in this case we are going to select the following key motor aspects:\n",
    "\n",
    "* Speech (mdsupdrs3_1)\n",
    "* Rigidity (max of mdsupdrs3_3a-e)\n",
    "* Gait (mdsupdrs3_10)\n",
    "* Freezing (mdsupdrs3_11)\n",
    "* Postural stability (mdsuprds3_12)\n",
    "* Postural tremor (max of mdsupdrs15a-b)\n",
    "* Kinetic tremor (max of mdsupdrs16a-b)\n",
    "* Rest tremor (max of mdsupdrs3_17a-d)\n",
    "* Bradykinesia (max of mdsupdrs3_4,mdsupdrs3_8, mdsupdrs3_14)\n",
    "* Dyskinesias (max of mdsupdrs4_1-4_2)\n",
    "* Motor fluctuations (max of mdsupdrs4_3-4_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds_updrs_names=[\"speech\", \"rigidity\", \"gait\", \"freezing\", \n",
    "                 \"postural_stability\", \"tremor_post\", \"tremor_kin\",\"tremor_rest\",\n",
    "                 \"bradykinesia\", \"dyskinesias\", \"motor_fluctuations\"]\n",
    "\n",
    "mds_updrs= pd.DataFrame(columns=mds_updrs_names)\n",
    "\n",
    "mds_updrs[\"speech\"] = data[\"mdsupdrs3_1\"]\n",
    "\n",
    "rigidity_cols = [\"mdsupdrs3_3a\", \"mdsupdrs3_3b\", \"mdsupdrs3_3c\", \"mdsupdrs3_3d\", \"mdsupdrs3_3e\"]\n",
    "mds_updrs[\"rigidity\"] = data[rigidity_cols].max(axis=1)\n",
    "\n",
    "mds_updrs[\"gait\"] = data[\"mdsupdrs3_10\"]\n",
    "\n",
    "mds_updrs[\"freezing\"] = data[\"mdsupdrs3_11\"]\n",
    "\n",
    "mds_updrs[\"postural_stability\"] = data[\"mdsupdrs3_12\"]\n",
    "\n",
    "postural_tremor_cols = [\"mdsupdrs3_15a\", \"mdsupdrs3_15b\"]\n",
    "mds_updrs[\"tremor_post\"] = data[postural_tremor_cols].max(axis=1)\n",
    "\n",
    "kinetic_tremor_cols = [\"mdsupdrs3_16a\", \"mdsupdrs3_16b\"]\n",
    "mds_updrs[\"tremor_kin\"] = data[kinetic_tremor_cols].max(axis=1)\n",
    "\n",
    "rest_tremor_cols = [\"mdsupdrs3_17a\", \"mdsupdrs3_17b\", \"mdsupdrs3_17c\", \"mdsupdrs3_17d\"]\n",
    "mds_updrs[\"tremor_rest\"] = data[rest_tremor_cols].max(axis=1)\n",
    "\n",
    "bradykinesia_cols = [\"mdsupdrs3_4a\", \"mdsupdrs3_4b\", \"mdsupdrs3_5a\", \"mdsupdrs3_5b\", \"mdsupdrs3_6a\", \"mdsupdrs3_6b\", \n",
    "                     \"mdsupdrs3_7a\", \"mdsupdrs3_7b\", \"mdsupdrs3_8a\", \"mdsupdrs3_8b\", \"mdsupdrs3_14\"]\n",
    "mds_updrs[\"bradykinesia\"] = data[bradykinesia_cols].max(axis=1)\n",
    "\n",
    "dyskinesias_cols = [\"mdsupdrs4_1\", \"mdsupdrs4_2\"]\n",
    "mds_updrs[\"dyskinesias\"] = data[dyskinesias_cols].max(axis=1)\n",
    "\n",
    "motor_fluctuations_cols = [\"mdsupdrs4_3\", \"mdsupdrs4_4\", \"mdsupdrs4_5\", \"mdsupdrs4_6\"]\n",
    "mds_updrs[\"motor_fluctuations\"] = data[motor_fluctuations_cols].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>rigidity</th>\n",
       "      <th>gait</th>\n",
       "      <th>freezing</th>\n",
       "      <th>postural_stability</th>\n",
       "      <th>tremor_post</th>\n",
       "      <th>tremor_kin</th>\n",
       "      <th>tremor_rest</th>\n",
       "      <th>bradykinesia</th>\n",
       "      <th>dyskinesias</th>\n",
       "      <th>motor_fluctuations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speech  rigidity  gait  freezing  postural_stability  tremor_post  \\\n",
       "0       3.0       3.0   1.0       1.0                 0.0          1.0   \n",
       "1       2.0       3.0   1.0       0.0                 2.0          1.0   \n",
       "2       1.0       2.0   1.0       0.0                 1.0          1.0   \n",
       "3       2.0       2.0   0.0       0.0                 0.0          1.0   \n",
       "4       2.0       1.0   2.0       0.0                 2.0          2.0   \n",
       "..      ...       ...   ...       ...                 ...          ...   \n",
       "397     1.0       0.0   1.0       0.0                 0.0          0.0   \n",
       "398     0.0       0.0   0.0       0.0                 0.0          2.0   \n",
       "399     1.0       0.0   1.0       0.0                 0.0          2.0   \n",
       "400     2.0       0.0   1.0       0.0                 0.0          2.0   \n",
       "401     0.0       3.0   1.0       0.0                 0.0          1.0   \n",
       "\n",
       "     tremor_kin  tremor_rest  bradykinesia  dyskinesias  motor_fluctuations  \n",
       "0           0.0          0.0           3.0          1.0                 2.0  \n",
       "1           1.0          0.0           1.0          1.0                 1.0  \n",
       "2           1.0          0.0           2.0          1.0                 0.0  \n",
       "3           1.0          0.0           2.0          0.0                 3.0  \n",
       "4           1.0          2.0           2.0          1.0                 1.0  \n",
       "..          ...          ...           ...          ...                 ...  \n",
       "397         0.0          0.0           1.0          1.0                 1.0  \n",
       "398         2.0          2.0           1.0          0.0                 1.0  \n",
       "399         0.0          2.0           0.0          0.0                 0.0  \n",
       "400         0.0          2.0           3.0          0.0                 0.0  \n",
       "401         1.0          1.0           2.0          0.0                 1.0  \n",
       "\n",
       "[402 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mds_updrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - Socio-demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "socio_demographic = pd.DataFrame(columns=original_socio_demographic_cols)\n",
    "socio_demographic[\"patnum\"] = data[\"patnum\"].values\n",
    "socio_demographic[\"age\"] = data[\"age\"].values\n",
    "socio_demographic[\"sex\"] = data[\"sex\"].values\n",
    "socio_demographic[\"pdonset\"] = data[\"pdonset\"].values\n",
    "socio_demographic[\"durat_pd\"] = data[\"durat_pd\"].values\n",
    "\n",
    "# Change sex codes from (0,1) to (male, female)\n",
    "socio_demographic[\"sex\"] = socio_demographic[\"sex\"].astype(\"category\")\n",
    "socio_demographic[\"sex\"].cat.categories = [\"male\", \"female\"]\n",
    "\n",
    "socio_demographic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 - Hoehn-Yahr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoehn_yahr = pd.DataFrame(columns=original_hoehn_yahr_cols)\n",
    "hoehn_yahr = data[\"hy\"]\n",
    "hoehn_yahr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Impute missing data\n",
    "\n",
    "First, we need to transform MDS_UPDRS columns to categorical format to allow the imputer to recognize them as such. Then combine both the nmss and mds_updrs variables data in a single dataset and impute all their missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "cat_mds_updrs = pd.DataFrame(columns=mds_updrs.columns)\n",
    "for col in mds_updrs.columns:\n",
    "    cat_mds_updrs[col] = mds_updrs[col].astype(\"category\")\n",
    "    \n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "imputed_mds_updrs = imputer.fit_transform(cat_mds_updrs)\n",
    "imputed_mds_updrs = pd.DataFrame(imputed_mds_updrs, columns = mds_updrs.columns)\n",
    "\n",
    "# numerical\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer(random_state=0)\n",
    "imputed_nmss = imputer.fit_transform(nmss)\n",
    "imputed_nmss = pd.DataFrame(imputed_nmss, columns = nmss.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Combine and generate the final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([socio_demographic, hoehn_yahr], axis = 1)\n",
    "final_df.to_csv(\"./mds_parkinson_info.csv\", index=False, na_rep=\"?\")\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 22)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([imputed_nmss, imputed_mds_updrs], axis = 1)\n",
    "train_df.to_csv(\"./mds_parkinson_train.csv\", index=False, na_rep=\"?\")\n",
    "train_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
